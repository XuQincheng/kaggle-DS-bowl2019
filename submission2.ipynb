{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in train.csv\n",
      "Reading in train_labels.csv\n",
      "Reading in test.csv\n",
      "Reading in specs.csv\n"
     ]
    }
   ],
   "source": [
    "print('Reading in train.csv')\n",
    "train_data = pd.read_csv(path/'train.csv')\n",
    "print('Reading in train_labels.csv')\n",
    "train_labels = pd.read_csv(path/'train_labels.csv')\n",
    "print('Reading in test.csv')\n",
    "test_data = pd.read_csv(path/'test.csv')\n",
    "print('Reading in specs.csv')\n",
    "specs = pd.read_csv(path/'specs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the size of the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 778.73 Mb (18.2% reduction)\n",
      "Mem. usage decreased to  0.49 Mb (48.2% reduction)\n",
      "Mem. usage decreased to 79.40 Mb (18.2% reduction)\n",
      "Mem. usage decreased to  0.01 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_data = reduce_mem_usage(train_data)\n",
    "train_labels = reduce_mem_usage(train_labels)\n",
    "test_data = reduce_mem_usage(test_data)\n",
    "specs = reduce_mem_usage(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to decompose dates into more relevant parts\n",
    "def explode_date(col):\n",
    "    dayofyear = col.dt.dayofyear\n",
    "    weekofyear = col.dt.weekofyear\n",
    "    weekday = col.dt.weekday\n",
    "    month = col.dt.month\n",
    "    year = col.dt.year\n",
    "    hour = col.dt.hour\n",
    "    quarter = col.dt.quarter\n",
    "    return pd.DataFrame({'dayofyear':dayofyear,\n",
    "                         'weekofyear':weekofyear,\n",
    "                         'weekday':weekday,\n",
    "                         'quarter':quarter,\n",
    "                         'month':month,\n",
    "                         'year':year,\n",
    "                         'hour':hour})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main funtion that aggregates the sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(install_id,data,is_train_data=True):\n",
    "    rows = []\n",
    "    for idx,df in tqdm(data.groupby('installation_id')):\n",
    "        rows.extend(reduce_data_per_user(df))\n",
    "    data = pd.DataFrame(rows)\n",
    "    if is_train_data:\n",
    "        return train_labels[['game_session','accuracy_group']]\\\n",
    "                        .merge(data,on='game_session',how='inner')\\\n",
    "                        .drop(['game_session'],axis=1)\n",
    "    else:\n",
    "        return data.groupby('installation_id',as_index=False).apply(lambda x: x.iloc[-1]).drop(['game_session'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>info</th>\n",
       "      <th>args</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b9272f4</td>\n",
       "      <td>The end of system-initiated feedback (Correct)...</td>\n",
       "      <td>[{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df4fe8b6</td>\n",
       "      <td>The end of system-initiated feedback (Incorrec...</td>\n",
       "      <td>[{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3babcb9b</td>\n",
       "      <td>The end of system-initiated instruction event ...</td>\n",
       "      <td>[{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f0836bf</td>\n",
       "      <td>The end of system-initiated instruction event ...</td>\n",
       "      <td>[{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab3136ba</td>\n",
       "      <td>The end of system-initiated instruction event ...</td>\n",
       "      <td>[{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                                               info  \\\n",
       "0  2b9272f4  The end of system-initiated feedback (Correct)...   \n",
       "1  df4fe8b6  The end of system-initiated feedback (Incorrec...   \n",
       "2  3babcb9b  The end of system-initiated instruction event ...   \n",
       "3  7f0836bf  The end of system-initiated instruction event ...   \n",
       "4  ab3136ba  The end of system-initiated instruction event ...   \n",
       "\n",
       "                                                args  \n",
       "0  [{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...  \n",
       "1  [{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...  \n",
       "2  [{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...  \n",
       "3  [{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...  \n",
       "4  [{\"name\":\"game_time\",\"type\":\"int\",\"info\":\"mill...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_description_dict = {row.event_id:row.info for idx,row in specs.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_titles = set(train_data.title.unique()).union(set(test_data.title.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduces data with respect to each installation id\n",
    "def reduce_data_per_user(user_dataframe):\n",
    "    event_counts = {'total_events':0,'clips_count':0,'assessment_count':0,'activity_count':0,'game_count':0,\n",
    "                    'correct_events_count':0,'incorrect_events_count':0}\n",
    "    specific_event_counts = dict(zip(specs.event_id,[0 for _ in range(specs.shape[0])]))\n",
    "    unique_titles_counts = dict(zip(unique_titles,[0 for _ in range(len(unique_titles))]))\n",
    "    median_session_times = []\n",
    "    df_features = []\n",
    "    for idx,session in user_dataframe.groupby('game_session'):\n",
    "        if session.type.iloc[0]=='Assessment':\n",
    "            assessment_info = {'assess_world':session.world.iloc[0],\n",
    "                               'assess_title':session.title.iloc[0],\n",
    "                               'game_session':session.game_session.iloc[0],\n",
    "                               'installation_id':session.installation_id.iloc[0]\n",
    "                              }\n",
    "            \n",
    "            df_features.append({**event_counts,**assessment_info,**specific_event_counts,\n",
    "                                **unique_titles_counts})\n",
    "            event_counts['assessment_count'] += (session.type == 'Assessment').sum()\n",
    "            unique_titles_counts[session.iloc[0].title]+=1\n",
    "        else:\n",
    "            event_counts['total_events'] += session.event_id.count()\n",
    "            event_counts['clips_count'] += (session.type == 'Clip').sum()\n",
    "            event_counts['activity_count'] += (session.type == 'Activity').sum()\n",
    "            event_counts['game_count'] += (session.type == 'Game').sum()\n",
    "            event_counts['correct_events_count'] += (session.event_id\n",
    "                                                     .map(event_description_dict)\n",
    "                                                     .str.contains('Correct').sum())\n",
    "            event_counts['incorrect_events_count'] += (session.event_id\n",
    "                                                       .map(event_description_dict)\n",
    "                                                       .str.contains('Incorrect').sum())\n",
    "            specific_event_counts.update(dict(session.event_id.value_counts()))\n",
    "            unique_titles_counts[session.iloc[0].title]+=1\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219999ffbf28444e85148f015d4d8da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9217114f85954113905bc96fa458bf8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_reduced = reduce_data(train_labels.installation_id.unique(),train_data)\n",
    "test_reduced = reduce_data(test_data.installation_id.unique(),test_data, is_train_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reduced.to_csv(path/'train_reduced.csv')\n",
    "test_reduced.to_csv(path/'test_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reduced = pd.read_csv(path/'train_reduced.csv',index_col=0)\n",
    "test_reduced = pd.read_csv(path/'test_reduced.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import cohen_kappa_score,confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb\n",
    "from rfpimp import *\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds = list(set(train_reduced.assess_world.unique()).union(test_reduced.assess_world.unique()))\n",
    "titles = list(set(train_reduced.assess_title.unique()).union(test_reduced.assess_title.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,val = train_test_split(train_reduced,test_size=.2)\n",
    "# X_col_names = [col for col in train_reduced.columns if col != 'accuracy_group']\n",
    "# train_x = train.loc[:,X_col_names]\n",
    "# train_y = train.loc[:,'accuracy_group']\n",
    "# val_x = val.loc[:,X_col_names]\n",
    "# val_y = val.loc[:,'accuracy_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col_names = [col for col in train_reduced.columns if col not in ['accuracy_group','installation_id']]\n",
    "train_x = train_reduced.loc[:,X_col_names]\n",
    "train_y = train_reduced.loc[:,'accuracy_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTENC([7,8])\n",
    "train_x_smote,train_y_smote = smote.fit_resample(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_smote = pd.DataFrame(train_x_smote,columns=X_col_names)\n",
    "train_x_smote['installation_id'] = 1\n",
    "train_x['installation_id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,x,y):\n",
    "    cv_scores = cross_val_score(model,x,y,scoring=make_scorer(cohen_kappa_score,weights='quadratic'),cv=5,n_jobs=5)\n",
    "    cv_mean_score = cv_scores.mean()\n",
    "    cv_sd = cv_scores.std()\n",
    "    train_score = cohen_kappa_score(model.fit(x,y).predict(x),y,weights='quadratic')\n",
    "    print(f'Train score:{train_score}')\n",
    "    print(f'Cross Validation Mean: {cv_mean_score:.3f} SD: {cv_sd:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([('onehot1',OneHotEncoder(),['assess_world']),\n",
    "                                  ('onehot2',OneHotEncoder(),['assess_title']),\n",
    "                                  ('drop', 'drop',['installation_id'])],\n",
    "                                  remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([('col_transform',preprocessor),\n",
    "                 ('cls',RandomForestClassifier(n_estimators=200,\n",
    "                                               max_features = int(np.sqrt(train_x.shape[1])),\n",
    "                                               min_samples_leaf=15,\n",
    "                                               max_depth=None,\n",
    "                                               n_jobs=8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest SMOTE results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('col_transform',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('onehot1',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  ['assess_world']),\n",
       "                                                 ('onehot2',\n",
       "                                                  OneHot...\n",
       "                ('cls',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=20, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=15,\n",
       "                                        min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=8,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Random Forest SMOTE results')\n",
    "#evaluate_model(rf_pipe,train_x_smote,train_y_smote)\n",
    "rf_pipe.fit(train_x_smote,train_y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(model,test_data):\n",
    "    install_id = test_data.installation_id.to_numpy()\n",
    "    test_predictions = model.predict(test_data.drop(['installation_id'],axis=1))\n",
    "    submission_df = pd.DataFrame({'installation_id':install_id,\n",
    "                                  'accuracy_group':test_predictions})\n",
    "    return submission_df\n",
    "test = prepare_submission(rf_pipe,test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
